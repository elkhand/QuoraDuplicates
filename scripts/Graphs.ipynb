{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loss vs Dev loss\n",
    "\n",
    "Siamese model with Relu layer\n",
    "\n",
    "Configs:\n",
    "\n",
    "    max_length = 35 # longest sequence to parse\n",
    "    n_classes = 2\n",
    "    dropout = 0.95\n",
    "    embed_size = 100 # todo: make depend on input\n",
    "    hidden_size = 1000\n",
    "    batch_size = 32\n",
    "    n_epochs = 100\n",
    "    max_grad_norm = 10.\n",
    "    lr = 0.0003\n",
    "    lr_decay_rate = 0.9\n",
    "    embeddings_trainable = True\n",
    "    pos_weight = 1.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grep -ri \"/F1\" exp_march9_relu_pred.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.667/0.721/0.693/0.6207\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.663/0.788/0.720/0.5820\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.702/0.759/0.729/0.5693\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.645/0.850/0.733/0.5825\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.686/0.805/0.741/0.6046\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.696/0.797/0.743/0.6573\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.725/0.766/0.745/0.7906\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.717/0.775/0.745/0.8866\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.742/0.746/0.744/1.1029\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.689/0.808/0.743/1.1627\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.737/0.741/0.739/1.3495\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.732/0.746/0.739/1.4553\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.721/0.771/0.745/1.4865\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.724/0.761/0.742/1.5525\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.699/0.787/0.740/1.6079\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.731/0.745/0.738/1.7580\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.703/0.785/0.742/1.7212\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.708/0.762/0.734/1.7768\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.704/0.780/0.740/1.7909\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.724/0.753/0.738/1.9301\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.722/0.757/0.739/1.8995\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.736/0.741/0.739/1.8957\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.719/0.758/0.738/2.0086\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.719/0.761/0.739/2.0253\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.710/0.776/0.741/2.0534\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.729/0.750/0.739/2.1094\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.722/0.750/0.736/2.0988"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1Scores= \"\"\"2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.667/0.721/0.693/0.6207\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.663/0.788/0.720/0.5820\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.702/0.759/0.729/0.5693\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.645/0.850/0.733/0.5825\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.686/0.805/0.741/0.6046\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.696/0.797/0.743/0.6573\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.725/0.766/0.745/0.7906\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.717/0.775/0.745/0.8866\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.742/0.746/0.744/1.1029\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.689/0.808/0.743/1.1627\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.737/0.741/0.739/1.3495\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.732/0.746/0.739/1.4553\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.721/0.771/0.745/1.4865\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.724/0.761/0.742/1.5525\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.699/0.787/0.740/1.6079\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.731/0.745/0.738/1.7580\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.703/0.785/0.742/1.7212\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.708/0.762/0.734/1.7768\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.704/0.780/0.740/1.7909\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.724/0.753/0.738/1.9301\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.722/0.757/0.739/1.8995\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.736/0.741/0.739/1.8957\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.719/0.758/0.738/2.0086\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.719/0.761/0.739/2.0253\n",
    "2528/2528 [==============================] - 65s    INFO:P/R/F1: 0.710/0.776/0.741/2.0534\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.729/0.750/0.739/2.1094\n",
    "2528/2528 [==============================] - 66s    INFO:P/R/F1: 0.722/0.750/0.736/2.0988\"\"\"\n",
    "f1ScoresLines = f1Scores.split(\"\\n\")\n",
    "#print f1ScoresLines, len(f1ScoresLines)\n",
    "devLosses=[]\n",
    "f1Values=[]\n",
    "for line in f1ScoresLines:\n",
    "    lineSplit = line.split(\"/\")\n",
    "    devLoss = lineSplit[-1]\n",
    "    devLosses.append(devLoss)\n",
    "    f1Values.append(lineSplit[-2])\n",
    "    #print devLoss\n",
    "    \n",
    "    \n",
    "print \"Dev Losses\",devLosses\n",
    "print \"\\n\"\n",
    "print \"F1 values\",f1Values\n",
    "print \"\\n\"\n",
    "print \"Max F1: \", max(f1Values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grep -ri \"7589/7589\" exp_march9_relu_pred.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7589/7589 [==============================] - 949s - train loss: 0.6809   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 940s - train loss: 0.5799   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.5121   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 943s - train loss: 0.4429   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 940s - train loss: 0.3691   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.2915   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 943s - train loss: 0.2182   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.1605   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.1202   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 942s - train loss: 0.0926   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0732   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 942s - train loss: 0.0618   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0529   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 943s - train loss: 0.0462   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 942s - train loss: 0.0409   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 942s - train loss: 0.0366   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0337   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 940s - train loss: 0.0306   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0297   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0260   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0251   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0243   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 942s - train loss: 0.0220   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0207   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0206   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0202   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 942s - train loss: 0.0169   INFO:Evaluating on development data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLossesStr=\"\"\"7589/7589 [==============================] - 949s - train loss: 0.6809   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 940s - train loss: 0.5799   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.5121   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 943s - train loss: 0.4429   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 940s - train loss: 0.3691   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.2915   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 943s - train loss: 0.2182   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.1605   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.1202   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 942s - train loss: 0.0926   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0732   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 942s - train loss: 0.0618   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0529   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 943s - train loss: 0.0462   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 942s - train loss: 0.0409   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 942s - train loss: 0.0366   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0337   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 940s - train loss: 0.0306   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0297   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0260   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0251   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0243   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 942s - train loss: 0.0220   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0207   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0206   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 941s - train loss: 0.0202   INFO:Evaluating on development data\n",
    "7589/7589 [==============================] - 942s - train loss: 0.0169   INFO:Evaluating on development data\"\"\"\n",
    "trainLossesStr = trainLossesStr.split(\"\\n\")\n",
    "#print f1ScoresLines, len(f1ScoresLines)\n",
    "trainLosses=[]\n",
    "for line in trainLossesStr:\n",
    "    lineSplit = line.split(\"train loss:\")\n",
    "    lineSplit = lineSplit[1]\n",
    "    lineSplit = lineSplit.split(\" \")\n",
    "    trainLoss = lineSplit[1]\n",
    "    trainLosses.append(trainLoss)\n",
    "    #print trainLoss\n",
    "print \"Train Losses\",trainLosses\n",
    "print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "fig.savefig('trainLossVSDevLoss.png', dpi=100)\n",
    "epochs=[i for i in range(len(trainLosses))]\n",
    "\n",
    "ax.plot(epochs, trainLosses, label='trainLoss') #'k--', \n",
    "ax.plot(epochs,devLosses,  label='devLoss') # 'k:', \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "\n",
    "# Now add the legend with some customizations.\n",
    "legend = ax.legend(loc='best', shadow=True)\n",
    "\n",
    "# The frame is matplotlib.patches.Rectangle instance surrounding the legend.\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "\n",
    "# Set the fontsize\n",
    "for label in legend.get_texts():\n",
    "    label.set_fontsize('large')\n",
    "\n",
    "for label in legend.get_lines():\n",
    "    label.set_linewidth(1.5)  # the legend line width\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
